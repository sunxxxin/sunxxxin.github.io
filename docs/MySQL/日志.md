# 日志

## undo log

undo log 是为了在事务执行的过程中发生崩溃，能通过undo log日志回滚到事务之前的数据

每当innodb引擎对一条记录执行增删改的时候，都会把修改的信息记录到undo log里,然后先写入buffer pool里面的undo页面

在插入记录的时候，把主键记录下来这样，回滚的时候只要找到这个主键值对应的记录删除就行

在删除记录的时候，把记录里的内容都记下来，这样在回滚的时候把这条记录插入到表里就好了

在更新的时候要把旧值都记录下来，这样在回滚的时候再把这些列更新为旧值就好了

一条记录的每一次更新操作产生的undo log 都有一个 roll_pointer 和一个trx_id

通过trx_id可以知道记录是被哪个事务修改的

通过roll_pointer指针可以将这些undo log串成一个链表,这个链表就被称为版本链

undo log还有另一个作用就是,通过readview+undo log 实现mvcc(多版本并发控制)

## Buffer pool

mysql中的数据都是存在磁盘中的,当我们更新一条记录的时候,先从磁盘读取改记录然后在内存中修改这条记录.修改完之后会将记录缓存在Buffer pool(缓存池),这样再有下次查询语句命中了这条记录,就可以直接读取缓存中的记录不需要从磁盘中读取了

有了这个buffer pool后:

当读取数据的时候,如果buffer poll 有这个数据,客户端就会直接读取buffer pool中的数据,否则再去磁盘中读取

当修改数据时,如果数据存在于buffer pool中,那直接修改buffer pool 中数据所在的页,然后将其设置为脏页,为了减少磁盘i/o不会立即将脏页写入磁盘,后续由后台线程选择一个合适的时机将脏页写入到磁盘

### Buffer pool缓存什么?

索引页,数据页,undo页,插入缓存,自适应哈希索引,锁信息

#### 查询一条记录,就只需要缓存一条记录么?

不是的

当查询一条记录时,innodb会把整个页的数据加载到buffer pool中,将页加载到buffer pool后,再通过页里的页目录去定位到某条具体的记录

## redo log

   buffer pool是基于内存的,但是内存不一定可靠假如停电重启的话,没来得及落盘的脏页数据就会丢失

为了防止断电导致的数据丢失问题,当有一条记录需要更新的时候,innodb引擎就会先更新内存(同时标记为脏页),然后将本次对这个页的修改以redo log 的形式记录下来,这个时候更新就算完成了

后续,innodb引擎会在适当的时候,由后台线程将缓存在buffer pool的脏页刷新到磁盘里,这就是WAL(write-ahead logging)技术

WAL技术指的是,MySQL的写操作并不是立即写到磁盘上,而是先写日志,然后在合适的时间写到磁盘上.





![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/mysql/how_update/wal.png?image_process=watermark,text_5YWs5LyX5Y-377ya5bCP5p6XY29kaW5n,type_ZnpsdHpoaw,x_10,y_10,g_se,size_20,color_0000CD,t_70,fill_0)

### 什么是redo log?

redo log 是物理日志,记录了 某个数据页做了什么修改,比如对xxx表空间中的yyy数据页zzz偏移量的地方做了aaa修改,每当执行一个事务就会产生这样的一条或者多条物理日志

在事务提交的时候,只要先将redo log 持久化磁盘即可,可以不需要等到将缓存在buffr pool里的脏数据持久化到磁盘

当崩溃的时候,虽然脏数据还没有持久化,但是redo log已经持久化,接着MySQL重启后,可以根据redo log的内容,将数据恢复到最新的状态

#### redo log 和undo log 区别在哪?

undo log 记录了此次事务  **开始前**的数据状态,记录的是更新前的值;

redo log 记录了此次事务 **完成后**的数据状态,记录的是更新之后的值;

有了redo log ,再通过WAL技术,InnoDB就可以保证即使数据库发生异常重启,之前已提交的记录都不会丢失,这个能力称为crash-safe(崩溃恢复).redo log保证了事务四大特性中的持久性

#### redo log 要写到磁盘上,数据也要写到磁盘上,为什么要多次一举?

写redo log 是追加操作,**顺序写** (循环写)

 写数据是先找到位置然后再写**随机写**

这样就能提升MySQL磁盘写入性能,并且还能实现崩溃恢复功能

#### 产生的redo log是直接写入磁盘么?

redo log也有自己的缓存区 redo log buffer,每当产生一条redo log 时,会先写入到redo log buffer ,后续在持久化到磁盘如下图



![事务恢复](https://cdn.xiaolincoding.com/gh/xiaolincoder/mysql/how_update/redologbuf.webp)

redo log buffer 默认大小是16MB可以通过 innodb_log_Buffer_size参数动态的调整大小,增大它的大小可以让MySQL处理大事务时不必写入磁盘,进而提升io性能

#### redo log 什么时候刷盘?

一般有以下时机

MySQL正常关闭的时候

redo log buffer 中记录的写入量大于其内存的一半的时候

innodb的后台线程每隔1秒,将redo log buffer 持久化到磁盘

每次事务提交的时候都将缓存在redo log buffer 里的redo log直接持久化到磁盘(这个策略由innodb_flush_log_trx_commit参数控制)

redo log 文件写满了怎么办?

默认情况下 innodb存储引擎有一个重做日志文件组(redo log Group),重做日志文件组由两个redo log文件组成,这两个redo日志的文件叫:ib_logfile0ib_logfile1.

![](photo/重做日志文件组.drawio.webp)

这个两个文件成环形的 ,采用循环写的方式,从头开始写道末尾就又回到开头,相当于一个环形,redo log 是为了防止buffer pool中的脏页丢失而设计的,只要buffer pool里面的脏页缓存到磁盘中变为干净页,redo log的记录就没用了,所有可以采用一边写一边删的形式

![](photo/checkpoint.webp)

## binlog

#### binlog和redo log的区别

##### 1.适用对象不同:

binlog 是MySQL的server层实现的日志,所有存储引擎都可以使用;

redo log 是innodb存储引擎实现的日志;

##### 2.文件格式不同:

binlog有三种格式类型,分别是STATEMENT,ROW,MIXED

STATEMENT:每一条修改的数据都会被记录到binlog中(相当于记录了逻辑操作,使用针对这种格式,binlog可以称为逻辑日志),主从复制中slave端再根据sql语句重现.;但STATEMENT对于动态函数会出现问题,比如说执行now主从的数据就会不一致

ROW: 记录行的数据最终被修改成什么样了(这种就不能称为逻辑日志了),这样就不会出现动态函数的问题,但是缺点是每行数据的变化结果都会被记录,比如批量执行updata语句,更新多少行数据就会产生多少条记录,使binlog文件过大,但是人家默认模式只要记录一个updata语句

mixed:包含了STATEMENT和ROW两种模式,会根据不同情况自动使用两个模式



redo log 是物理日志,记录的是在某个数据页做了什么修改,比如对xxx表空间中的yyy数据页zzz偏移量的地方做了aaa更新;

##### 3.写入方式不同:

binlog是追加写,写满一个文件,就创建一个新的文件继续写,不会覆盖以前的日志,保存的是全量的日志.

redo log 是循环写,日志空间大小是固定,全部写满就从头开始,保存未被刷入磁盘的脏也日志.

##### 4.用途不同

binlog用于数据恢复,主从复制;

redo log 用于掉电等故障恢复.

假如数据库不小心被删除了,就不能用redo log恢复数据,因为它一边写一遍删,所有得用binlog恢复

### 主从复制是怎么实现的?

 主从复制依赖binlog,也就是记录MySQL上的所有变化并以二进制的形式存在磁盘上.复制的过程就是将binlog中的数据从主库传输到从库上.

这个过程一般是异步的,也就是主库上执行事务操作的线程不会等待binlog的线程同步完成

![MySQL 主从复制过程](https://cdn.xiaolincoding.com/gh/xiaolincoder/mysql/how_update/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%E8%BF%87%E7%A8%8B.drawio.png?image_process=watermark,text_5YWs5LyX5Y-377ya5bCP5p6XY29kaW5n,type_ZnpsdHpoaw,x_10,y_10,g_se,size_20,color_0000CD,t_70,fill_0)

MySQL集群的主从复制过程分为三个阶段:

写入binlog:主库写入binlog日志,提交事务,并更新本地存储数据

同步binlog:把binlog复制到从库上,每个从库把binlog写入到暂存日志中

回放binlog:回访binlog,并更新存储引擎中的数据

具体过程如下

MySQL主库在收到客户端提交事务的请求之后,会先写入binlog,再提交事务,更新存储引擎中的数据,事务提交完成后,返回给客户端"操作成功"的响应.

从库会创建一个专门的i/o线程,连接主库的log dump线程,来接收主库的binlog日志,再把binlog信息写入relay log的中继日志里,再返回给主库"复制成功"的响应

从库会创建一个用于回放的binlog的线程,去读取relay log 中继日志,然后回放binlog更新存储引擎中的数据,最终实现主从的数据一致性.

这样完成主从复制之后,就可以在写数据时只写主库,在读数据的时候只读从库,这样即使写请求会锁表或者锁记录,也不会影响读请求的执行

#### 从库是不是越多越好?

不是,因为从库数量增加,从库连接上来的i/o线程也越多,主库也要创建同样多的log dump 线程来处理复制的请求,对主库资源销毁比较高,同时还要受限于主库的网络带宽.

#### MySQL主从复制还有哪些模型?

同步复制:MySQL主库提交事务的线程要等待所有从库的复制成功响应,才返回客户端结果,这种方式在实际的项目中,基本上没法用,主要有两个原因:一是性能很差,因为要复制到所有节点才返回响应;二是可用性也很差,主库和所有从库任何一个数据库出问题,都会影响业务

异步复制(默认模型):主库提交事务的线程不会等待binlog同步到从库,就返回客户端结果,这种模式一旦主库宕机,数据就会发生丢失

半同步复制:MySQL5.7之后增加的一种复制方式,事务线程不用等待所有的主库复制成功响应,只要一部分复制成功的响应回来就行,比如一主二从的集群,只要数据成功复制到任意一个从库上,主库的事务线程就可以返回给客户端.这种半同步复制的方式,兼顾了异步复制和同步复制的优点,即使出现主库宕机,至少还有一个从库有最新的数据,不存在数据丢失的风险

#### binlog什么时候刷盘?

事务执行过程中,先把日志写到 binlog cache(server层的cache),事务提交的时候,再把binlog cache 写到 binlog文件中

一个事务的binlog是不能被拆开的,因为无论这个事务有多大(比如很多条语句),也要保证一次性写入.这是因为有一个线程只能同时有一个事务在执行的设定,所以每当执行一个begin/start transaction 的时候,就会默认提交上一个事务,这样如果一个事务的binlog被拆开的时候,在从库执行就会被当作多个事务分段执行,这样破坏了原子性,是有问题的

MySQL给每个线程分配了一片内存用于缓冲binlog,该内存叫binlog cache,参数binlog_cache_size用于控制单个线程内binlog cache 所占内存的大小,如果超过了这个参数规定的大小,就要暂存到磁盘

什么时候binlog cache会写到binlog文件?

在事务提交的时候,执行器把binlog cache里的完整事务写入到binlog文件中,并清空binlog cache 





![binlog cach](https://cdn.xiaolincoding.com/gh/xiaolincoder/mysql/how_update/binlogcache.drawio.png)



虽然每个线程都有自己的binlog cache ,但是最终都写到同一个binlog文件:

图中的write,指的就是把日志写入到binlog文件,但是并没有把数据持久化到磁盘,因为数据还缓存在文件系统中的page cache里,write的写入速度还是比较快的,因为不涉及磁盘i/o

图中的fsync,才是将数据持久化到磁盘的操作,这里会涉及磁盘i/o,所以频繁的fync会导致磁盘的i/o升高

MySQL提供一个sync_binlog参数来控制数据库的binlog刷到磁盘上的频率:

sync_binlog=0的时候,表示每次提交事务都只write不fsync,后续交由操作系统决定何时将数据持久化到磁盘

sync_binlog=0的时候,表示每次提交事务都会write,然后马上执行fsync;

sync_binlog=n的时候,表示每次提交事务都write,但积累n个事务后才fsync

### update语句的执行过程.

update uers set name =  '王五' where id =1;

连接器:与数据库建立连接

查询缓存:update 一般不会命中所以直接跳过

解析器:  对语法进行检查

预处理器:检查语句中的表或者此字段是否存在

优化器:将sql语句的执行方案确定下来,包括使用什么索引了等等

执行器开始执行:

​	1存储器调用存储引擎的接口,通过主键索引获取id=1这一行的记录

​			如果这行记录在buffer pool中,直接返回给执行器更新

​			如果不在,将数据页从磁盘读入到buffer pool,返回给执行器

​	2.执行器得到聚簇索引记录后,会看一下更新之前的记录和更新之后的记录是否一样:

​			如果一样就不进行后续更新流程

​			如果不一样的话就把更新之前的记录和更新之后的记录都当作参数传给innodb层,让innodb真正的执行更新记录的操作;

3.开启事务,innodb层更新记录前,首先要记录相应的undo log ,因为这是更新操作,需要把被更新的列的旧值记下来,也就是要生成一条undo log ,undo log会写入buffer pool中的undo 页面,不过在内存修改undo页面之后,需要记录对应的redo log

4.innodb层开始更加记录,首先会更新内存(同时标记为脏页),然后将记录写到redo log里面,这时候更新就算完成了,为了减少磁盘i/o,不会立即将脏页写入磁盘,后续由后台线程选择一个合适的时机将脏页写入磁盘,这就是wal技术,MySQL的写操作并不是立即写到磁盘上而是先写redo日志,然后在合适的时间再将修改的数据写入到磁盘上

5至此一条更新语句的执行流程就完成了,然后开始记录该语句对应的binlog,此时记录的binlog会被保存到binlog cache ,并没有刷新到硬盘上的binlog日志,在事务提交的时候才会统一将该事务运行过程中所有的inlog刷新到磁盘

6然后事务提交, 接下来是两阶段提交

#### 两阶段提交

事务提交之后,redo log 和binlog 都要持久化到磁盘,但是这是两个独立的逻辑,可能出现半成功的状态,这样就造成两份日志之间的逻辑不一致.

举个栗子

假如出现了半成功状态

1如果redo log刷入磁盘之后,MySQL突然宕机了,而binlog 还没来得及写入.

​		MySQL重启后,通过redo log能将buffer pool 中这个值更新为新值,但是binlog没有写入所以从库还是旧值

2.如果binlog输入磁盘后,MySQL突然宕机了而redolog还没写入

​		MySQL重启后从库是新值,但是主库是旧值,这样旧造成了主从数据库的值不一样

所以这时候MySQL采用两阶段提交的方式来保证要么全部执行成功要么全部执行失败

两阶段提交就是把单个事务的提交拆分为了两个阶段,分别是准备阶段和提交阶段

#### 两阶段提交的过程

在MySQL的innodb存储引擎中,开启binlog的情况下,MySQL会同时维护binlog日志与innodb的redo  log,为了保证这两个日志的一致性,MySQL使用了内部xa事务,内部事务由binlog作为协作者,存储引擎是参与者

当客户端执行commit语句或者在自动提交的情况下,MySQL内部开启一个xa事务,分别两阶段完成xa事务的提交

![两阶段提交](https://cdn.xiaolincoding.com/gh/xiaolincoder/mysql/how_update/%E4%B8%A4%E9%98%B6%E6%AE%B5%E6%8F%90%E4%BA%A4.drawio.png?image_process=watermark,text_5YWs5LyX5Y-377ya5bCP5p6XY29kaW5n,type_ZnpsdHpoaw,x_10,y_10,g_se,size_20,color_0000CD,t_70,fill_0)

两阶段就是将redo log的写入拆分为了两个步骤

prepare阶段:写内部事务xa的xid写入redo log,同时将 redo log对应的事务状态设置为prepare,然后将redo log 持久化到磁盘

commit阶段:把xid写入到binlog,然后将binlog持久化到磁盘(如果sync_binlog=1),调用引擎的提交事务接口将redo log的状态设置为commit,

如果发生发生崩溃 就拿着redo log 的xid去binlog里查看是否存在xid

​	如果binlog里有说明redolog和binlog已经刷盘了就提交事务

​	如果binlog里没有说明 redolog刷盘,binlog还没刷盘就回滚事务

总的来说两阶段提交是以binlog是否写成功为事务提交成功的标志,因为binlog写成功了,就意味着在binlog中能找到与redolog相同的xid

事务没提交的时候 redo log 就会持久化到磁盘,但是binlog必须在事务提交之后才会持久化到磁盘

#### 两阶段提交有什么问题?

1.磁盘i/o次数高:对于双1配置,每个事务提交都会进行两次fsync(刷盘),一次是redo log刷盘,另一次是bin log刷盘

2.锁竞争激烈:两阶段提交虽然能够保证单事务两个日志的内容一致,但是在多事务的情况下,却不能保证两者的提交顺序一致,因此,在两阶段提交的流程基础上,还需要加一个锁来保证提交的原子性,从而保证多事务的情况下,两个日志的提交顺序一致

在早期的MySQL版本中,通过使用prepare_commit_mutex锁来保证事务提交的顺序,在一个事务获取到锁时才能进入prepare阶段,一直到commit阶段结束才能释放锁,下个事务才可以继续prepare操作

#### 组提交

为了解决commit阶段锁竞争激烈的情况MySQL引入binlog组提交机制,当有多个事务提交的时候,会将多个binlog刷盘操作合并成一个,从而减少磁盘i/o次数

